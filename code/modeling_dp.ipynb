{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/athletes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are Na values in some columns. Fill with 0\n",
    "df['total_lift'] = df['candj'].fillna(0) + df['snatch'].fillna(0) + df['deadlift'].fillna(0) + df['backsq'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vars = ['region','gender', 'eat', 'background', 'experience', 'schedule', 'howlong','age','height','weight','candj','snatch','deadlift','backsq']\n",
    "cats = ['region','gender', 'eat', 'background', 'experience', 'schedule', 'howlong']\n",
    "numcs = ['age','height','weight','candj','snatch','deadlift','backsq']\n",
    "\n",
    "# x = pd.get_dummies(x, columns=cats) # encode categorical variables\n",
    "\n",
    "x = df[numcs].fillna(0) # NAs in numeric columns, fill 0 if any\n",
    "\n",
    "y = df['total_lift']\n",
    "\n",
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer import DPGradientDescentGaussianOptimizer\n",
    "\n",
    "# model hyperparameters\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Define privacy parameters\n",
    "l2_norm_clip = 1.0  # Clipping norm\n",
    "noise_multiplier = 0.5  # Noise multiplier\n",
    "num_microbatches = 1  # Number of microbatches\n",
    "learning_rate = 0.1  # Learning rate\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(x_train.shape[1],)),   # Input layer for the number of features\n",
    "    tf.keras.layers.Dense(64, activation='relu'),       # Hidden layer 1\n",
    "    tf.keras.layers.Dense(32, activation='relu'),       # Hidden layer 2\n",
    "    tf.keras.layers.Dense(1)                            # Output layer (for regression)\n",
    "])\n",
    "\n",
    "# Create the optimizer with differential privacy\n",
    "optimizer = DPGradientDescentGaussianOptimizer(\n",
    "    l2_norm_clip=l2_norm_clip,\n",
    "    noise_multiplier=noise_multiplier,\n",
    "    num_microbatches=num_microbatches,\n",
    "    learning_rate=learning_rate)  # Use `dp_sum_query` for better privacy guarantees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24023 samples\n",
      "Epoch 1/10\n",
      " 9056/24023 [==========>...................] - ETA: 0s - loss: 457830.3421 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 20:53:08.188684: W tensorflow/c/c_api.cc:304] Operation '{name:'TFOptimizer_10/iterations/Assign' id:1430 op device:{requested: '', assigned: ''} def:{{{node TFOptimizer_10/iterations/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_INT64, validate_shape=false](TFOptimizer_10/iterations, TFOptimizer_10/iterations/Initializer/initial_value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24023/24023 [==============================] - 0s 17us/sample - loss: 1816160.4360\n",
      "Epoch 2/10\n",
      "24023/24023 [==============================] - 0s 11us/sample - loss: 11412045.9028\n",
      "Epoch 3/10\n",
      "24023/24023 [==============================] - 0s 10us/sample - loss: 51005334.3679\n",
      "Epoch 4/10\n",
      "24023/24023 [==============================] - 0s 10us/sample - loss: 109840196.4537\n",
      "Epoch 5/10\n",
      "24023/24023 [==============================] - 0s 10us/sample - loss: 235321514.7710\n",
      "Epoch 6/10\n",
      "24023/24023 [==============================] - 0s 10us/sample - loss: 246502523.1933\n",
      "Epoch 7/10\n",
      "24023/24023 [==============================] - 0s 9us/sample - loss: 263255616.1625\n",
      "Epoch 8/10\n",
      "24023/24023 [==============================] - 0s 9us/sample - loss: 206586494.0312\n",
      "Epoch 9/10\n",
      "24023/24023 [==============================] - 0s 10us/sample - loss: 199034655.8362\n",
      "Epoch 10/10\n",
      "24023/24023 [==============================] - 0s 10us/sample - loss: 222725446.1941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b0bbbe50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 198169759.73359972\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss = model.evaluate(x_test, y_test)\n",
    "print(f'Test loss: {test_loss}')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7343.46\n",
      "Mean Squared Error (MSE): 198169753.58\n",
      "Root Mean Squared Error (RMSE): 14077.28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Compute regression metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)  # Calculate RMSE\n",
    "\n",
    "# Display the metrics summary\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute DP epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD performed over 24023 examples with 256 examples per iteration, noise\n",
      "multiplier 0.5 for 10 epochs with microbatching, and no bound on number of\n",
      "examples per user.\n",
      "\n",
      "This privacy guarantee protects the release of all model checkpoints in addition\n",
      "to the final model.\n",
      "\n",
      "Example-level DP with add-or-remove-one adjacency at delta = 1e-05 computed with\n",
      "RDP accounting:\n",
      "    Epsilon with each example occurring once per epoch:       138.688\n",
      "    Epsilon assuming Poisson sampling (*):                    139.347\n",
      "\n",
      "No user-level privacy guarantee is possible without a bound on the number of\n",
      "examples per user.\n",
      "\n",
      "(*) Poisson sampling is not usually done in training pipelines, but assuming\n",
      "that the data was randomly shuffled, it is believed the actual epsilon should be\n",
      "closer to this value than the conservative assumption of an arbitrary data\n",
      "order.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(compute_dp_sgd_privacy.compute_dp_sgd_privacy_statement(x_train.shape[0],\n",
    "                                    batch_size=256,\n",
    "                                    noise_multiplier=noise_multiplier,\n",
    "                                    num_epochs=epochs,\n",
    "                                    delta=.00001\n",
    "                                    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
